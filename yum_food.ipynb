{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2bjBqjC09eAJ7CJtFQFk/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtificialT800/FoodModel/blob/main/yum_food.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "42_aMLKpOoOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkTKWyUwOcbh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data"
      ],
      "metadata": {
        "id": "GbGaYMAXOtyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = torchvision.datasets.Food101(root=\"data\",\n",
        "                                          split=\"train\",\n",
        "                                          download=True,\n",
        "                                          transform=data_transform)\n",
        "\n",
        "test_data = torchvision.datasets.Food101(root='data',\n",
        "                                         split='test',\n",
        "                                         download=True,\n",
        "                                         transform=data_transform)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data, shuffle=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
        "test_dataloader = DataLoader(dataset=test_data, shuffle=False, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "mZWhR_iKOs0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes"
      ],
      "metadata": {
        "id": "t1AjnT9zOx4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "  def __init__(self, input_units, output_units, hidden_units):\n",
        "    super().__init__()\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_units, out_channels=hidden_units, kernel_size=1, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=1, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=1, stride=1)\n",
        "    )\n",
        "\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=1, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=1, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=1, stride=1)\n",
        "    )\n",
        "    self.block_3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=1, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=1, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=1, stride=1)\n",
        "    )\n",
        "\n",
        "    self.Classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*227*227, out_features=output_units)\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.Classifier(self.block_3(self.block_2(self.block_1(x))))\n",
        "\n",
        "model = CNNModel(input_units=3, hidden_units=10, output_units=len(class_names))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "TfCM3dOH1Tyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loss function and optimizer + helper functions"
      ],
      "metadata": {
        "id": "3FMOGsyCO45G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),\n",
        "                             lr=0.001)\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred))*100\n",
        "  return acc\n",
        "\n",
        "def time_taken(start: float,\n",
        "               end: float,\n",
        "               device: torch.device = device):\n",
        "  total_time = end-start\n",
        "  return total_time\n"
      ],
      "metadata": {
        "id": "7Vm8MpMq3geh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "start = timer()\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  #Training\n",
        "\n",
        "  model.train()\n",
        "  train_loss, train_acc = 0, 0\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "\n",
        "    acc = accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "    train_acc += acc\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(train_dataloader)\n",
        "  train_acc /= len(train_dataloader)\n",
        "\n",
        "  #Testing\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    total_test_loss, total_test_acc = 0, 0\n",
        "    for batch, (X_test, y_test) in enumerate(test_dataloader):\n",
        "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "      test_pred = model(X_test)\n",
        "\n",
        "      test_loss = loss_fn(test_pred, y_test)\n",
        "      total_test_loss += test_loss\n",
        "\n",
        "      test_acc = accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
        "      total_test_acc += test_acc\n",
        "\n",
        "    total_test_loss /= len(test_dataloader)\n",
        "    total_test_acc /= len(test_dataloader)\n",
        "\n",
        "  print(f\"Epochs: {epoch}| Train Loss: {train_loss}, Train Accuracy: {train_acc}% | Test Loss: {total_test_loss}, Test Accuracy: {total_test_acc}%\")\n"
      ],
      "metadata": {
        "id": "8ba0nDuz4KPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting on new/custom images"
      ],
      "metadata": {
        "id": "jCGJ7CGUPSC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_preds(model: torch.nn.Module):\n",
        "  img_path = input(\"Enter the image path: \")\n",
        "  img = torchvision.io.read_image(img_path)\n",
        "  img = img.type(torch.float32) / 255\n",
        "  img = img.to(device)\n",
        "  img_transform = transforms.Compose([\n",
        "      transforms.Resize(size=(224, 224))\n",
        "  ])\n",
        "  img = img_transform(img)\n",
        "  img = img.unsqueeze(dim=0)\n",
        "\n",
        "  model = model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    img_pred = model(img)\n",
        "    img_pred_probs = torch.softmax(img_pred, dim=1)\n",
        "\n",
        "  image = torch.argmax(img_pred_probs, dim=1).cpu()\n",
        "  plt.figure(figsize=(12, 7))\n",
        "  img = img.to(\"cpu\")\n",
        "  plot_img = img.squeeze()\n",
        "  plt.imshow(plot_img.permute(1, 2, 0))\n",
        "  plt.title(f\"Pred: {class_names[image]} | Prob: {img_pred_probs.max()}\")\n",
        "  plt.axis(False)\n",
        "  print(img_pred_probs)"
      ],
      "metadata": {
        "id": "ol_H7xHnPGwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_preds(model=model)"
      ],
      "metadata": {
        "id": "I2JgmVtRPIaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save the model if the accuracy is >= 85%"
      ],
      "metadata": {
        "id": "IcCeBXWTTIPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if int(total_test_acc) >= 85:\n",
        "  torch.save(obj=model.state_dict(), f='model.pt')\n",
        "else:\n",
        "  print(\"Accuracy isn't good enough...\")"
      ],
      "metadata": {
        "id": "fsZUMHtPTQ4K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}