{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPkAgTUsnJnWBbrTlMhWN0T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtificialT800/FoodAI/blob/main/yum_food.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "42_aMLKpOoOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkTKWyUwOcbh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data"
      ],
      "metadata": {
        "id": "GbGaYMAXOtyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = Path(\"data/\")\n",
        "img_path = data_path / \"food\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "\n",
        "if img_path.is_dir():\n",
        "    print(f\"{img_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {img_path} directory, creating one...\")\n",
        "    img_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download the data\n",
        "    with open(data_path / \"data.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/ArtificialT800/FoodAI/raw/main/food_101.zip\")\n",
        "        print(\"Downloading dataset...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip the data\n",
        "    with zipfile.ZipFile(data_path / \"data.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping data...\")\n",
        "        zip_ref.extractall(img_path)"
      ],
      "metadata": {
        "id": "ABtCk4WGtFuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train and test split"
      ],
      "metadata": {
        "id": "_V5BXPBOtQRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = img_path / \"train\"\n",
        "test_dir = img_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "aOZXrHe8tPNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Augmentation"
      ],
      "metadata": {
        "id": "UeS7MfSTU7Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(root=train_dir,\n",
        "                                  transform=data_transform,\n",
        "                                  target_transform=None,\n",
        "                                  )\n",
        "\n",
        "test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform=data_transform,\n",
        "                                 target_transform=None)\n",
        "\n",
        "print(train_data, test_data)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data, shuffle=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
        "test_dataloader = DataLoader(dataset=test_data, shuffle=False, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "mZWhR_iKOs0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes"
      ],
      "metadata": {
        "id": "t1AjnT9zOx4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "A7mVoIaDhDI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Building the Vision Model\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "  def __init__(self, input_units, output_units, hidden_units):\n",
        "    super().__init__()\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_units, out_channels=hidden_units, kernel_size=2, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=2, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "    )\n",
        "\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=2, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=2, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "    )\n",
        "    self.block_3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=2, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=2, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "    )\n",
        "\n",
        "    self.block_4 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=2, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=2, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "    )\n",
        "    self.block_5 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=2, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=2, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "    )\n",
        "\n",
        "\n",
        "    self.Classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*229*229, out_features=output_units)\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.Classifier(self.block_5(self.block_4(self.block_3(self.block_2(self.block_1(x))))))\n",
        "\n",
        "model = CNNModel(input_units=3, hidden_units=16, output_units=len(class_names))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "TfCM3dOH1Tyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loss function and optimizer + helper functions"
      ],
      "metadata": {
        "id": "3FMOGsyCO45G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss function\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#Optimizer\n",
        "\"\"\"\n",
        "You could always experiment with other optimizers too, like SGD or Adagrad!\n",
        "\n",
        "More optimizers at -> \"https://pytorch.org/docs/stable/optim.html#algorithms\"\n",
        "\n",
        "\"\"\"\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),\n",
        "                             lr=0.001)\n",
        "\n",
        "#Accuracy function\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred))*100\n",
        "  return acc\n",
        "\n",
        "\n",
        "#Keeping track of how long the model took to train\n",
        "def time_taken(start: float,\n",
        "               end: float,\n",
        "               device: torch.device = device):\n",
        "  total_time = end-start\n",
        "  return total_time\n",
        "\n",
        "\n",
        "#Function to see the model's training curves\n",
        "def plot_loss_curves(results):\n",
        "  \"\"\"Plots training curves of a trained model\"\"\"\n",
        "  train_loss = results[\"train_loss\"]\n",
        "  total_test_loss = results[\"test_loss\"]\n",
        "\n",
        "  train_acc = results[\"train_acc\"]\n",
        "  total_test_acc = results[\"test_acc\"]\n",
        "\n",
        "  epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "  plt.figure(figsize=(15, 7))\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs, train_loss, label=\"Train Loss\")\n",
        "\n",
        "  plt.plot(epochs, total_test_loss, label=\"Test Loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs, train_acc, label=\"Train Accuracy\")\n",
        "  plt.plot(epochs, total_test_acc, label=\"Test Accuracy\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "\n",
        "#Function to predict on custom images\n",
        "def plot_preds(model: torch.nn.Module):\n",
        "  img_path = input(\"Enter the image path: \")\n",
        "  img = torchvision.io.read_image(img_path)\n",
        "  img = img.type(torch.float32) / 255\n",
        "  img = img.to(device)\n",
        "  img_transform = transforms.Compose([\n",
        "      transforms.Resize(size=(224, 224))\n",
        "  ])\n",
        "  img = img_transform(img)\n",
        "  img = img.unsqueeze(dim=0)\n",
        "\n",
        "  model = model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    img_pred = model(img)\n",
        "    img_pred_probs = torch.softmax(img_pred, dim=1)\n",
        "\n",
        "  image = torch.argmax(img_pred_probs, dim=1).cpu()\n",
        "  plt.figure(figsize=(12, 7))\n",
        "  img = img.to(\"cpu\")\n",
        "  plot_img = img.squeeze()\n",
        "  plt.imshow(plot_img.permute(1, 2, 0))\n",
        "  plt.title(f\"Pred: {class_names[image]} | Prob: {(img_pred_probs.max()):.4f}\")\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "7Vm8MpMq3geh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Training and testing Loop\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "start = timer()\n",
        "\n",
        "EPOCHS = 150\n",
        "\n",
        "results = {\"train_loss\": [],\n",
        "          \"train_acc\": [],\n",
        "          \"test_loss\": [],\n",
        "          \"test_acc\": []\n",
        "          }\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "  #Training\n",
        "\n",
        "  model.train()\n",
        "  train_loss, train_acc = 0, 0\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "\n",
        "    acc = accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "    train_acc += acc\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(train_dataloader)\n",
        "  train_acc /= len(train_dataloader)\n",
        "\n",
        "  #Testing\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    total_test_loss, total_test_acc = 0, 0\n",
        "    for batch, (X_test, y_test) in enumerate(test_dataloader):\n",
        "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "      test_pred = model(X_test)\n",
        "\n",
        "      test_loss = loss_fn(test_pred, y_test)\n",
        "      total_test_loss += test_loss\n",
        "\n",
        "      test_acc = accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
        "      total_test_acc += test_acc\n",
        "\n",
        "    total_test_loss /= len(test_dataloader)\n",
        "    total_test_acc /= len(test_dataloader)\n",
        "\n",
        "    results[\"train_loss\"].append(train_loss.to(\"cpu\"))\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(total_test_loss.to(\"cpu\"))\n",
        "    results[\"test_acc\"].append(total_test_acc)\n",
        "\n",
        "  print(f\"Epochs: {epoch}| Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}% | Test Loss: {total_test_loss:.4f}, Test Accuracy: {total_test_acc:.4f}%\")"
      ],
      "metadata": {
        "id": "8ba0nDuz4KPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save the model if the accuracy is >= 85%"
      ],
      "metadata": {
        "id": "IcCeBXWTTIPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if int(total_test_acc) >= 85:\n",
        "  print(f\"Test Accuracy is pretty good..\\nCurrent Test Accuracy is: {total_test_acc:.3f}%\")\n",
        "  torch.save(obj=model.state_dict(), f='model.pt')\n",
        "\n",
        "elif int(train_acc) >= 95:\n",
        "  torch.save(obj=model.state_dict(), f='train_model.pt')\n",
        "  print(\"Train Accuracy is good.. \\nCurrent Test Accuracy is: {total_test_acc:.3f}%\")\n",
        "\n",
        "else:\n",
        "  print(\"Accuracy isn't good enough...\")\n",
        "  print(f\"Current Test Accuracy is: {total_test_acc:.3f}%\")"
      ],
      "metadata": {
        "id": "fsZUMHtPTQ4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plotting Loss curves"
      ],
      "metadata": {
        "id": "wZBWobH2f4-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(results=results)"
      ],
      "metadata": {
        "id": "L8Bsc0HEgN6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting on new/custom images"
      ],
      "metadata": {
        "id": "jCGJ7CGUPSC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_preds(model=model)"
      ],
      "metadata": {
        "id": "I2JgmVtRPIaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion"
      ],
      "metadata": {
        "id": "evJlEv7zw3Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "That's all for this small project. You could could always adjust the hyperparameters of the model to make it perform even better.\n",
        "If there are any issues, you could always create a new issue in my github repo, \"https://github.com/ArtificialT800/FoodModel/issues\"..\n",
        "The model's dataset was simplified as I wanted to keep this project beginner friendly. Thank you!!!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KNZMo3Gbw4pa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}